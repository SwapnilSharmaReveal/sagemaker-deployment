{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "import sagemaker\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sagemaker boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hf_token = \"<Add your hugging face token here>\"\n",
    "aws_secret_access_key = \"< your aws access key >\"\n",
    "aws_access_key_id = \"< your aws access key id >\"\n",
    "aws_iam_role = \"< your aws iam role >\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.Session(aws_access_key_id=\"AKIA3KLMGCP4FU4I2ETJ\", aws_secret_access_key=\"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\")\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = \"arn:aws:iam::778152842232:role/sagemaker-deployment-role\"\n",
    "\n",
    "sess = sagemaker.Session(boto_session=boto_session, default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model_id = \"meta-llama/Llama-2-13b-chat-hf\"  # model id from huggingface.co/models\n",
    "number_of_gpus = 4  # number of gpus to use for inference and tensor parallelism\n",
    "health_check_timeout = (\n",
    "    300  # Increase the timeout for the health check to 5 minutes for downloading the model\n",
    ")\n",
    "instance_type = \"ml.g5.12xlarge\"  # instance type to use for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_image = get_huggingface_llm_image_uri(backend=\"huggingface\", session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"llama-2-13b-chat\")\n",
    "llm_model = HuggingFaceModel(\n",
    "    role=role,\n",
    "    image_uri=llm_image,\n",
    "    sagemaker_session=sess,\n",
    "    env={\n",
    "        \"HF_MODEL_ID\": hf_model_id,\n",
    "        \"SM_NUM_GPUS\": str(number_of_gpus),\n",
    "        \"HUGGING_FACE_HUB_TOKEN\": hf_token,\n",
    "    },\n",
    ")\n",
    "\n",
    "llm = llm_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    container_startup_health_check_timeout=health_check_timeout,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
